{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pymongo import MongoClient\n",
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the max_length limit\n",
    "nlp.max_length = 2500000  # Set it to a value that accommodates your text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client['article_recommendation']\n",
    "article_collection = db['article']\n",
    "\n",
    "# Find the first document in the collection\n",
    "# first_article = article_collection.find_one()\n",
    "# abstract = first_article['abstract']\n",
    "\n",
    "# Find all documents in the collection\n",
    "all_articles = article_collection.find()\n",
    "\n",
    "# List to store all abstracts\n",
    "all_abstracts = []\n",
    "\n",
    "# Iterate over all documents\n",
    "for article in all_articles:\n",
    "    # Check if the document has an abstract field\n",
    "    if 'abstract' in article:\n",
    "        abstract = article['abstract']\n",
    "        all_abstracts.append(abstract)\n",
    "\n",
    "# Concatenate all abstracts into a single string\n",
    "all_abstracts_text = \" \".join(all_abstracts)\n",
    "\n",
    "\n",
    "# Example text\n",
    "# text = \"This is an example sentence. John go to the school.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "doc = nlp(all_abstracts_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization:\n",
    "Tokenization is the process of splitting text into individual words or tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over tokens\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech (POS) Tagging:\n",
    "POS tagging assigns a grammatical label to each token, such as noun, verb, adjective, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over tokens with POS tags\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER):\n",
    "NER identifies named entities such as persons, organizations, locations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Removing Stopwords:\n",
    "Stopwords are common words (e.g., \"the\", \"is\", \"and\") that are often removed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "filtered_tokens = [token.text for token in doc if token.text.lower() not in STOP_WORDS]\n",
    "\n",
    "# Join filtered tokens back into a sentence\n",
    "filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "doc = nlp(filtered_text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out stopwords\n",
    "# filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "# filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tokens that are not punctuation\n",
    "filtered_tokens = [token.text for token in doc if token.is_punct == False]\n",
    "\n",
    "# Join the filtered tokens into a string\n",
    "clean_text = \" \".join(filtered_tokens)\n",
    "doc = nlp(clean_text)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Lemmatization:\n",
    "Lemmatization reduces words to their base or root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over tokens with lemmatized forms\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sentence from lemmatized tokens\n",
    "lemmatized_abstract = \" \".join([token.lemma_ for token in doc])\n",
    "lemmatized_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to preprocess the abstract\n",
    "def preprocess_abstract(abstract):\n",
    "    # Tokenize the abstract\n",
    "    tokens = nlp(abstract.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation, and lemmatize the tokens\n",
    "    processed_tokens = [token.lemma_ for token in tokens if token.text not in STOP_WORDS and token.text not in string.punctuation]\n",
    "    \n",
    "    # Join the processed tokens back into a string\n",
    "    preprocessed_abstract = ' '.join(processed_tokens)\n",
    "    \n",
    "    return preprocessed_abstract\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient()  # Update with your MongoDB connection URI\n",
    "db = client[\"article_recommendation\"]  # Update with your database name\n",
    "articles_collection = db[\"article\"]  # Update with your collection name\n",
    "\n",
    "# Retrieve articles from MongoDB\n",
    "articles = articles_collection.find()\n",
    "\n",
    "# Process each article\n",
    "for article in articles:\n",
    "    # Preprocess the abstract\n",
    "    preprocessed_abstract = preprocess_abstract(article[\"abstract\"])\n",
    "    \n",
    "    # Update the article in the collection with the preprocessed abstract\n",
    "    articles_collection.update_one({\"_id\": article[\"_id\"]}, {\"$set\": {\"preprocessed_abstract\": preprocessed_abstract}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = fasttext.load_model('../../cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.70015432e-02,  8.15567933e-03, -1.88383684e-02,  1.23793781e-01,\n",
       "        5.05270716e-03, -6.70323521e-02,  3.45998369e-02,  1.84294637e-02,\n",
       "       -7.64054060e-02, -4.19045091e-02, -8.06465298e-02,  1.28976656e-02,\n",
       "        2.00077564e-01,  1.82825729e-01,  2.11075842e-02,  7.39751160e-02,\n",
       "        1.44422576e-02, -2.42733415e-02,  4.43353727e-02, -2.89499313e-02,\n",
       "       -3.03028524e-02,  1.96899474e-03, -5.38224690e-02, -1.65010661e-01,\n",
       "        4.10782881e-02, -2.79612606e-03,  1.20798722e-02,  7.80077726e-02,\n",
       "       -1.24231517e-01,  9.36542973e-02,  1.25443518e-01, -4.22076993e-02,\n",
       "        1.87173914e-02, -1.19053960e-01, -3.97234261e-02,  3.18592042e-02,\n",
       "       -3.64079326e-03, -1.88531447e-02,  5.71619682e-02, -9.96990204e-02,\n",
       "        9.28039253e-02, -1.79177329e-01,  2.02885523e-04,  1.45949662e-01,\n",
       "       -1.19298488e-01,  2.01106481e-02, -2.17653401e-02,  5.99322319e-02,\n",
       "        1.02034425e-02,  1.73299946e-02, -9.40109342e-02,  2.78837830e-02,\n",
       "       -9.87280831e-02, -1.21910684e-01,  1.18924892e-02,  7.13354275e-02,\n",
       "       -1.04642689e-01, -3.74697223e-02, -6.73705786e-02,  7.45791849e-03,\n",
       "        1.18944589e-02,  3.27657126e-02, -7.45747089e-02,  4.26726863e-02,\n",
       "       -2.50711665e-02,  5.54383770e-02,  2.57515144e-02,  6.58904761e-02,\n",
       "        6.29670322e-02, -1.10323630e-01,  1.27817355e-02, -2.28800401e-01,\n",
       "       -4.63290624e-02,  5.63230291e-02, -2.28967428e-01, -2.76457705e-03,\n",
       "        1.12215713e-01,  9.11645405e-03,  1.77293383e-02, -3.46542746e-02,\n",
       "        6.07757568e-02,  6.01661652e-02, -1.06124831e-02,  6.26282841e-02,\n",
       "       -3.80302556e-02, -1.59125000e-01,  1.44064929e-02, -5.00600711e-02,\n",
       "        6.13152012e-02,  7.02601299e-02,  4.50852439e-02,  9.32816863e-02,\n",
       "        6.53656200e-02, -1.17487079e-02,  6.57974631e-02, -7.73745030e-03,\n",
       "       -9.31025576e-03, -3.03413458e-02, -1.42591447e-02, -4.58771102e-02,\n",
       "        1.90289877e-02,  6.10328577e-02,  1.07206360e-01,  1.07041627e-01,\n",
       "       -8.08774456e-02, -1.50443077e-01,  1.42960474e-02,  1.04355231e-01,\n",
       "        2.50205994e-02, -4.44108546e-02,  1.34724751e-01, -1.29666105e-02,\n",
       "        6.02255166e-02, -1.50240790e-02,  1.00721791e-01, -6.07931763e-02,\n",
       "       -1.28233373e-01, -1.28511321e-02, -7.75150135e-02,  7.11710155e-02,\n",
       "       -7.17846751e-02,  2.32814997e-03,  1.60706937e-01, -3.20767378e-03,\n",
       "       -3.41867656e-02,  1.23961642e-01, -3.46204974e-02, -1.15657650e-01,\n",
       "       -1.07521646e-01,  4.92567793e-02, -4.66027558e-02, -1.47359610e-01,\n",
       "        2.78421119e-03,  1.00165252e-02, -2.11927500e-02, -6.72350898e-02,\n",
       "        1.38401657e-01, -1.51315063e-01,  1.41579732e-02,  9.46018007e-03,\n",
       "        5.58394492e-02,  1.43871584e-03, -4.07826453e-02, -1.04453288e-01,\n",
       "        1.89576428e-02, -6.46253526e-02, -2.00816557e-01, -5.71718775e-02,\n",
       "        1.69055402e-01,  5.36719784e-02, -3.54669355e-02,  1.31655689e-02,\n",
       "       -3.43968570e-02, -7.20197558e-02, -1.19886011e-01,  1.91985141e-03,\n",
       "        7.31538534e-02,  2.42804885e-02,  7.55970478e-02,  5.49206659e-02,\n",
       "       -8.07701647e-02, -5.88235781e-02,  3.72170061e-02, -2.09487543e-01,\n",
       "        4.90664020e-02, -3.45959365e-02,  7.84536451e-02, -2.06569657e-02,\n",
       "        5.80293462e-02,  9.44344401e-02, -5.91469668e-02, -8.07700097e-04,\n",
       "        1.06073581e-01,  3.71135771e-04,  5.03538772e-02,  4.86647487e-02,\n",
       "        2.47735381e-02,  6.60691932e-02, -5.37526570e-02,  6.45508021e-02,\n",
       "       -1.27857607e-02,  7.04422146e-02,  2.52038799e-02, -6.94022775e-02,\n",
       "       -3.95657271e-02,  6.89128265e-02,  5.97311556e-02, -1.16366968e-01,\n",
       "        1.07618742e-01, -4.11170684e-02, -5.94441742e-02, -7.06123114e-02,\n",
       "        1.02064446e-01, -5.67908108e-04, -1.19896516e-01,  3.81347910e-02,\n",
       "        5.27033536e-03,  1.11462429e-01, -1.23539791e-02,  1.54471502e-01,\n",
       "       -3.66291441e-02,  8.36358219e-02,  7.29677305e-02, -1.41335034e-03,\n",
       "       -2.03797892e-02,  8.90103206e-02,  1.10245449e-02,  4.21358868e-02,\n",
       "        1.10418342e-01,  9.22219083e-02, -1.02480695e-01, -2.35873442e-02,\n",
       "        6.08111173e-03, -3.06916493e-03, -1.61892921e-02,  4.72077681e-03,\n",
       "        5.74680381e-02,  5.25933504e-02, -1.50644658e-02,  9.04936939e-02,\n",
       "       -3.48931062e-03, -1.46121085e-01, -7.24252611e-02,  8.96131992e-02,\n",
       "       -3.12228557e-02, -5.34620732e-02,  5.11336774e-02,  4.11617234e-02,\n",
       "       -3.83213535e-02,  7.01569617e-02, -4.07562926e-02,  5.74100874e-02,\n",
       "        1.17928786e-02,  1.04327291e-01, -1.53087256e-02, -4.66635935e-02,\n",
       "        6.95781037e-02,  5.40144742e-02,  2.11684834e-02, -6.47145659e-02,\n",
       "       -4.73226141e-03,  6.44419789e-02, -1.97040766e-01, -8.40479359e-02,\n",
       "        1.22763678e-01,  2.02672388e-02, -3.79657596e-02,  7.35505819e-02,\n",
       "       -9.58834141e-02,  8.65781605e-02, -1.82297915e-01,  8.23416859e-02,\n",
       "        1.16887912e-02, -6.59121480e-03,  1.02630630e-01,  6.62156567e-02,\n",
       "       -3.02871726e-02, -9.19438154e-02, -2.47561000e-02, -1.47944354e-02,\n",
       "        1.62278727e-01, -1.15151525e-01, -9.74430144e-03, -8.38155448e-02,\n",
       "       -2.70313900e-02,  5.40325120e-02, -3.08612734e-02,  9.29040760e-02,\n",
       "       -8.66650939e-02, -1.37688577e-01, -5.46395741e-02, -5.30129299e-02,\n",
       "       -5.01632206e-02, -5.63175045e-02, -1.33931320e-02,  1.08980685e-01,\n",
       "        1.11028850e-02,  3.88394445e-02, -6.61083013e-02,  1.56166162e-02,\n",
       "       -4.22378024e-03,  1.88123956e-02, -9.21699405e-02, -1.45736456e-01,\n",
       "       -1.08246639e-01, -2.63282321e-02,  4.13388163e-02,  3.41019966e-02,\n",
       "       -1.52945165e-02, -3.60713154e-02,  1.01884983e-01, -4.61598933e-02,\n",
       "       -7.13730305e-02,  9.44287628e-02,  9.07397717e-02, -9.61800218e-02,\n",
       "       -1.05385063e-02,  1.04262263e-01,  2.72203982e-03,  3.73943290e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vector embedding for a single word\n",
    "word_embedding = model.get_word_vector('word')\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.20564678e-02,  3.35800238e-02, -2.18866915e-02,  1.03436381e-01,\n",
       "       -4.20465022e-02, -7.09157586e-02,  1.89646464e-02,  3.62958163e-02,\n",
       "        8.37822072e-03, -7.26430714e-02, -4.14594412e-02, -1.50927966e-02,\n",
       "        1.77079570e-02,  9.17252973e-02,  4.17290628e-02,  5.53209372e-02,\n",
       "        5.23850434e-02, -2.83666775e-02,  1.02283200e-04, -6.09768033e-02,\n",
       "       -2.66362354e-02, -2.81010419e-02,  9.60057369e-04, -6.37210011e-02,\n",
       "        1.24849118e-02,  4.27029058e-02,  1.80861782e-02,  2.03714650e-02,\n",
       "       -1.91458035e-02,  9.76150036e-02,  2.62749121e-02,  4.45653535e-02,\n",
       "        4.37861308e-02, -1.23121291e-01, -3.74393351e-02, -4.68374044e-02,\n",
       "        1.38125811e-02,  4.69143540e-02, -2.24425383e-02,  3.88402678e-03,\n",
       "        2.34032907e-02, -2.84987241e-02, -1.53347040e-02,  8.29414278e-02,\n",
       "       -1.49825159e-02,  2.90117897e-02, -1.39033813e-02, -5.84693477e-02,\n",
       "        5.31740189e-02,  5.66520961e-04, -3.39121348e-03,  2.55819224e-02,\n",
       "       -8.31171572e-02, -1.67486072e-02, -6.16935315e-03, -2.40597762e-02,\n",
       "       -6.03654385e-02,  3.61694992e-02, -8.29915628e-02,  3.63318203e-03,\n",
       "       -1.25952950e-02,  3.23467106e-02,  8.95301066e-03, -1.14986133e-02,\n",
       "        1.01954695e-02, -1.31856576e-02,  4.22104746e-02,  3.31371389e-02,\n",
       "        2.08006315e-02, -4.55563925e-02,  1.58154052e-02, -1.99014656e-02,\n",
       "       -5.04826382e-02, -2.19944045e-02, -4.07165140e-02, -1.49151878e-02,\n",
       "        5.37816994e-02, -1.03750546e-02,  2.87087802e-02,  7.97200054e-02,\n",
       "        2.07246505e-02,  5.45354858e-02, -4.85431850e-02,  1.06814858e-02,\n",
       "        2.53775716e-02,  6.44718483e-03,  4.00026934e-03,  5.43770287e-03,\n",
       "       -1.76989790e-02,  3.34140286e-02, -1.11635122e-02, -2.53513753e-02,\n",
       "        1.58829004e-01, -5.05973697e-02,  1.23966606e-02,  3.18256766e-02,\n",
       "        4.10640687e-02,  6.06204867e-02,  2.94806808e-02,  2.18659937e-02,\n",
       "       -1.11353062e-02, -3.51474294e-03,  4.85806167e-02,  5.35360649e-02,\n",
       "       -4.40186113e-02,  4.94843647e-02,  2.13962365e-02,  9.28601064e-03,\n",
       "       -1.22391991e-02,  2.66525950e-02,  6.21551424e-02, -4.29877862e-02,\n",
       "       -1.76510718e-02,  8.29436854e-02, -9.55983251e-03,  2.32765963e-03,\n",
       "       -5.92441782e-02,  1.61459930e-02,  1.27052385e-02, -2.14880127e-02,\n",
       "        3.12433988e-02, -4.57748249e-02,  1.59543157e-02, -7.73980515e-03,\n",
       "       -4.04171422e-02,  2.78651454e-02, -2.91069169e-02, -4.22309712e-03,\n",
       "       -4.76764217e-02,  2.26867106e-02,  1.08327344e-02, -9.57603455e-02,\n",
       "        5.03464192e-02,  5.25252521e-02, -1.99226886e-02,  1.73872095e-02,\n",
       "        3.63166817e-02, -8.22189525e-02, -1.49415191e-02, -1.61416642e-02,\n",
       "       -5.15808091e-02,  5.19252121e-02, -6.32321462e-04, -4.98516634e-02,\n",
       "       -2.20905486e-02,  5.34485802e-02, -1.74336374e-01, -4.86588851e-02,\n",
       "       -2.00460460e-02, -8.75843503e-03, -5.04031666e-02,  6.10307530e-02,\n",
       "        2.88550183e-02, -1.82839744e-02, -6.99961632e-02,  5.32431267e-02,\n",
       "        1.08065061e-01, -1.54070798e-02,  5.97521737e-02, -1.73867196e-02,\n",
       "       -3.08845341e-02,  4.88270521e-02,  3.79229188e-02, -7.89981782e-02,\n",
       "        3.89987230e-02, -1.52132288e-02,  2.77036186e-02,  1.76392142e-02,\n",
       "        8.39263052e-02,  3.48474272e-02,  6.77972585e-02, -6.38506338e-02,\n",
       "        2.83379182e-02, -2.08128728e-02, -3.62535305e-02, -5.46834916e-02,\n",
       "       -2.27091797e-02,  1.78502966e-03, -3.13423648e-02,  9.51447245e-03,\n",
       "       -1.44591508e-02, -1.20005393e-02,  7.81808048e-04, -2.95118745e-02,\n",
       "       -2.34575570e-03, -4.10813093e-02,  8.88900086e-03, -3.19876894e-02,\n",
       "        3.57422084e-02, -4.88665849e-02, -4.59416583e-02,  9.48761962e-03,\n",
       "       -3.99424918e-02,  1.03868106e-02, -3.48619372e-02,  5.02788574e-02,\n",
       "        4.35611531e-02,  5.99646196e-02,  1.30737703e-02,  7.26401880e-02,\n",
       "       -8.21232945e-02,  9.34070125e-02,  5.63666970e-02, -3.49993352e-04,\n",
       "       -7.65347183e-02,  4.18829955e-02, -1.97042637e-02, -1.30132101e-02,\n",
       "        1.31750517e-02,  5.04220575e-02, -1.64212827e-02, -8.67528692e-02,\n",
       "       -2.87891598e-03,  4.78131510e-03,  7.18702078e-02,  3.66886929e-02,\n",
       "        3.24157625e-02, -1.19077694e-02, -1.25716971e-02,  2.65731942e-03,\n",
       "        1.01711303e-02,  2.50159781e-02,  3.04175243e-02, -2.90504210e-02,\n",
       "        1.63658559e-02, -5.55397384e-02,  8.06593001e-02, -5.71228564e-02,\n",
       "        2.03411430e-02, -2.48378031e-02, -9.78751760e-03,  4.45567407e-02,\n",
       "       -6.43002540e-02, -3.35686654e-02, -1.57076605e-02, -8.03619996e-03,\n",
       "        2.52972674e-02,  2.82493960e-02,  2.64056846e-02, -1.14493025e-02,\n",
       "       -3.61905172e-02,  7.90747069e-03, -6.92822412e-02, -6.69854209e-02,\n",
       "        1.47991285e-01,  2.51637325e-02, -1.67660583e-02,  4.60972860e-02,\n",
       "        4.26840708e-02, -2.38466263e-02, -1.42983785e-02,  2.95086987e-02,\n",
       "       -3.43272761e-02, -1.78032070e-02, -1.40753994e-03, -1.46488091e-02,\n",
       "        1.39079606e-02,  1.78564750e-02,  3.53460982e-02,  2.31961114e-03,\n",
       "        7.70608708e-03, -5.16220443e-02, -1.40231289e-03, -8.31104815e-04,\n",
       "        2.19427496e-02, -1.27253467e-02,  4.69760820e-02,  1.28720878e-02,\n",
       "       -1.97729561e-02, -3.39418985e-02, -7.26600289e-02, -5.40015846e-03,\n",
       "       -2.43150163e-03, -4.10235077e-02,  1.90820592e-03, -1.62223168e-02,\n",
       "       -6.89361617e-03, -2.17117108e-02, -5.52612357e-03, -2.74760891e-02,\n",
       "        1.06712161e-02, -3.83704416e-02, -9.17925686e-02, -4.50327396e-02,\n",
       "       -7.32177347e-02, -7.35444017e-03, -6.16462603e-02, -3.82616036e-02,\n",
       "       -1.97672099e-03,  6.70827925e-04,  3.72474641e-02, -7.73576461e-03,\n",
       "       -4.87601198e-02,  9.83340200e-03, -9.14113875e-03, -1.51143167e-02,\n",
       "        2.78497040e-02,  1.16496786e-01, -3.63057852e-03, -3.27349156e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vector embedding for a sentence\n",
    "sentence_embedding = model.get_sentence_vector('your sentence')\n",
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x211e5193a08>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['article_recommendation']\n",
    "collection = db['article']\n",
    "\n",
    "# Update each document in the collection to rename the vector_embedding field\n",
    "collection.update_many({}, {'$rename': {'vector_embedding': 'fasttext_vector_embedding'}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 385/385 [00:00<00:00, 64.2kB/s]\n",
      "Downloading: 100%|██████████| 422M/422M [03:05<00:00, 2.39MB/s] \n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 223k/223k [00:00<00:00, 719kB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Specify the SciBERT model name\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "# Load the SciBERT model\n",
    "scibert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Load the SciBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is an example sentence to tokenize.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = scibert_model(**inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_recommendation_system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
